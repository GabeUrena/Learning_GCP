Use Cloud Pub/Sub to integrate components of your application

Cloud Pub/Sub enables you to build your application on open multi-cloud or Hybrid architecture.

Use Cloud Pub/Sub to build loosely coupled applications, fan out messages to multiple subscribers, or rapidly ingest large volumes of data.

Common scenario:
Organizations have to rapidly ingest, transform, and analyze massive amounts of data.
  - A gaming application might receive and process user engagement and Clickstream data.
  - In the shipping industry, IoT applications might receive large amounts of sensor data from hundreds of sensors.

Pub-Sub Concepts*****
PUB/SUB is a fully managed real-time messaging architecture
- An application that publishes messages is called a publisher
- Publisher creates and publishes messages on a topic
- To receive messages, a subscriber application creates a subscription to a topic
- A subscription can use either the push or pull method for message delivery.
- The subscriber-only receives messages that are published after the subscription is created. 
- After receiving or processing each pending message, the subscriber sends an acknowledgment back to the Pub/Sub service
- Pub/sub removes acknowledged messages from the subscription queue of messages
- If the subscriber doesn't acknowledge a message before the acknowledgment deadline, Pub/Sub will resend the message to the subscriber
- Pub/Sub delivers each message to each subscriber at least once.
* Pub/Sub enables loosely coupled integration between the application components, acts as a buffer to handle spikes in data volume, and also supports other use cases.

Pub/Sub supports pull and push subscriptions
Pull subscription
 - The subscriber explicitly calls the pull method to request messages for delivery
 - Pub/Sub returns a message and acknowledgment ID.
 - To acknowledge receipt, the subscriber invokes the acknowledged method by using the acknowledgment ID
In a Pull subscription model, the subscriber could be Dataflow or any application that uses cloud-client libraries to retrieve messages
 - The subscriber controls the rate of delivery
 - A subscriber can modify the acknowledgment deadline to allow more time to process messages
 - To process messages rapidly multiple subscribers can pull from the same subscription.
 - The pull subscription model enables batch delivery and acknowledgments as well as massively parallel consumption
 - Use the pull subscription model when you need to process a very large volume of messages with high throughput
Push Subscription
 - Doesn't need to implement Google Cloud library methods to retrieve and process messages
 - Pub/Sub sends each message as an HTTP request to the subscriber at a preconfigured HTTP endpoint.

 - push endpoints can be a load balancer or an app engine standard application
    - the endpoint acknowledges the message by returning an HTTP success status code
    - a failure response indicates that the message should be sent again.
- Pub/Sub dynamically adjusts the rate of push requests based on the rate at which it receives successful responses.
- You can configure a default acknowledgment deadline for push subscriptions
- Pub/Sub will resend messages if the code doesn't acknowledge the message before the deadline.
* Use the push subscription model in environments where Google Cloud dependencies such as credentials and the client library can't be configured or multiple topics must be processed by the same webhook.
ideal when the HTTP endpoint will be invoked by Pub/Sub and other applications

When executing environments for subscribers you can develop highly scalable subscribers with Cloud Functions or Dataflow.
1. Cloud functions are triggered whenever a new message is received
     - Enables you to implement a serverless approach and build highly scalable systems.
2. Deploy your subscriber application on computing environments such as Compute Engine, Google Kubernetes Engine, or App Engine flexible environment.
     - Multiple instances of your application can spin up and split the workload by processing the messages in the topic.
         - each instance can automatically shut down when they're are very few messages to process.
     - you can enable elastic scaling using Pub/Sub metrics that are published to Cloud Monitoring

Use Pub/Sub for asynchronous processing and loose coupling.
Example 
                                       Pub/Sub   
              order        +------------------------------+         
Pulbisher Order service -> |Orders Topics -> Subscription | -> Subscriber Inentory Service
                           +------------------------------+
The order service acts as the publisher, It publishes messages that contain order information to the order topic and returns immediately
The inventory service acts as the subscriber. It might even be down when the publisher sends messages
The subscriber can start running a litter later and process the messages it is subscribed to.

Cloud Pub/Sub enables you to use a topic as a buffer to hold data that is coming in rapidly.
    - You might have multiple instances of a service generating large volumes of data, A downstream service that needs to process this data might become overwhelmed with the high velocity and volume of data
        - To address this issue, instances of your data-generating service can act as publishers and publish the data to a Cloud Pub/Sub topic.
        - Cloud Pub/Sub can reliably receive and store large volumes of rapidly incoming data.
        - The downstream service can then act as a subscriber and consume the data as a reasonable pace.
    - Your application can automatically scale up the number of instances of the subscriber to handle increased volumes of data

The publisher can push messages to a centralized Cloud Pub/sub-topic
Services that are interested in the information can simply subscribe to the topic.

-Cloud pub/sub delivers each message at least once
  - Subscribers can sometimes see duplicate messages
-Implement your publisher and subscriber in such a way that the application can perform item-potent operations
-The publisher can publish messages with a unique ID
-Your subscriber can use Cloud Datastore, Cloud FireStore, or Cloud Bigtable to store information about messages that have already been processed.
-Use the unique identifier as a Key

Whenever a message is received, the subscriber can check previously saved messages to see whether the incoming message is new and needs to be processed
If the message has already been processed, the subscriber can just discard the duplicate message.

Cloud Pub/Sub provides a highly scalable messaging architecture
  - Message ordering is not guaranteed
* Design your application to reduce or even eliminate dependencies on message ordering.
  - Message ordering is not relevant in use cases where your application is collecting statistics about the event
    - You don't need to process the statistics for related events in order
  - You don't need to be notified about the exact order of your contacts coming online if they all came on at the same time.
  - There are scenarios in which the final order of messages is important, but the order in which the individual messages are processed is not important.
      - Log events with time stamps may stream into the logging service from various sources.
      - The order of processing each log event is not important, however, eventually, your system should enable you to view log events ordered by time stamp.

There are scenarios where messages must be processed in the order in which they were published
  - Financial transactions must be processed in order
  - Online multiplayer games. (A player jumping over a wall, landing on an enemy, and collecting loot. Other players must see the same thing.)

Implement ordered processing of messages:
1. The subscriber knows the order in which messages must be processed.
  - The publisher can publish messages with a unique ID
  - Your subscriber can use Cloud Datastore to store information about messages that have been processed so far
  - When a new message is received, the subscriber can check whether this message should be processed immediately or the unique ID indicates that there are pending messages that should be processed first
2. The subscriber checks the oldest unacknowledged message in Cloud Monitoring metrics
 - The subscriber can store all messages in a persistent data store
 - It can check indistinct subscription oldest unacknowledged message metric that the Cloud Pub/Sub publishes to Stackdriver
 - The subscriber can compare the time stamp of the oldest acknowledged message against the published time stamps of the messages in Cloud Datastore.
 - All messages published before the oldest unacknowledged message are guaranteed to have been received so those messages can be removed from the persistent data store and processed in order.
